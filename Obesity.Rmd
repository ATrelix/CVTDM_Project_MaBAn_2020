---
title: "Data Mining Project (MaBAn 2020)"
subtitle: "Predicting obesity levels according to daily habits"

author: "by : Ángel Tomás-Ripoll & Laurence Tétreault-Falsafi"

output:
  pdf_document:
    toc: true
    
urlcolor: blue
geometry: "left=2.5cm,right=2.5cm,top=1cm,bottom=2.5cm"
  
---

# Introduction

##### For this project, our objective is to predict the expected weight level (in Kg) for a given person depending on certain daily habits (eating and physical activity) and on the person's age, gender and height. 

##### To do this, we found a quite interesting dataset (click here : http://archive.ics.uci.edu/ml/datasets/Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+) containing 2111 observations and 17 variables (mainly categorical). 

##### Please, find here a manually created metadata table :

##### {-}

```{r}

# To adjust the page margins when knitting to PDF :

library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=45),tidy=TRUE)

```


```{r message=FALSE, warning=FALSE}

# Used packages :
library(pander)
library(dplyr)
library(gt)
library(car)
library(ggplot2)
library(gridExtra)
library(psych)
library(corrplot)
library(ellipse)
library(dummies)
library(nnet)
library(class)
library(caret)
library(rpart)
library(rpart.plot)
library(ehaGoF)
library(forecast)
library(randomForest)

# Working Directory :
setwd("~/GitHub/CVTDM_Project_MaBAn_2020")


# Reading the data :
obesity <- read.csv("Obesity.csv", header=T, sep=",")
attach(obesity)

# Small metadata table :

tibble_table <- 
  tibble(
    "Variable Name" = c(colnames(obesity)[1:14], "", colnames(obesity)[15:17]),
    Description = c("Gender", "Age", "Height", "Weight", "Has a family member suffered or suffers from overweight?", "Do you eat high caloric food frequently?", "Do you usually eat vegetables in your meals?", "How many main meals do you have daily?", "Do you eat any food between meals?", "Do you smoke?", "How much water do you drink daily?", "Do you monitor the calories you eat daily?", "How often do you have physical activity?", "How much time do you use technological devices such as", "cell phone videogames, television, computer and others?", "How often do you drink alcohol?", "Which transportation do you usually use?", "Obesity level based on calculation of Mass Body Index")
  )

metadata <- gt(data = tibble_table)

metadata %>%
  tab_header(title = md("**Metadata**"),
             subtitle = "from the dataset we are using") %>%
  
  tab_source_note(source_note = "Based on information in : 
                  
  https://www.sciencedirect.com/science/article/pii/S2352340919306985")

```

##### {-}

##### Here is a small overview of the first observations :

##### {-}

```{r}

pander(head(obesity))

```

##### {-}

##### The variable of interest is the fourth one, the "Weight", so it will be our dependent variable.

##### We were "lucky" on the fact that this dataset has a quite high level of quality, because it has no missing observations, and our subsequent exploratory analysis will tell us if there are outliers to be handled with.


##### Once we are done with a Data Exploratory Analysis and with a proper Data Pre-Processing, we will develop several models in order to accurately predict the level of weight of each individual.

##### The models will be :

1. **Multiple Linear Regression** (not ANOVA since "Age" and "Height" are numerical)
2. **Regression tree** (complemented with a random forest / boosted trees / bagged trees)
3. **k-Nearest Neighbors**
4. **Ensemble Method**

##### We will deploy the best model based on error metrics and prediction performance.

##### At the very end, we will make a **Shiny App** available, in which any user can fill-in a questionnaire concerning daily habits, age and height. Then, the App will tell the user what is the expected weight according to those characteristics, and will present the result in two forms :

* The expected weight in Kg.

* The expected obesity level based on the Body Mass Index, following the classification comming from the World Health Organisation.

##### The user will also be able to **select the type of model** that will predict the results. That way, it will be interesting to see with just a few clicks how each model will yield different results.


##### {-}


# Data Pre-Processing


##### The first thing to do is to change the column names so that they are more visually meaningful!

##### {-}

```{r}

# Changing column names:

names(obesity)[5] = "family_history"
names(obesity)[6] = "eat_caloric"
names(obesity)[7] = "vegetables"
names(obesity)[8] = "main_meals"
names(obesity)[9] = "food_inbetween"
names(obesity)[12] = "monitor_cal"
names(obesity)[13] = "physical_act"
names(obesity)[14] = "tech_devices"
names(obesity)[15] = "alcohol"

```

##### {-}

```{r}

# Checking the dataset structure :

pander(str(obesity))

pander(summary(obesity))

```

##### {-}

##### Now, since many variables are in fact numerical and continuous between a range (for example `vegetables`, inside the range 1 to 3), we will transform them into categorical. This is, somehow, BINNING. For this, we will follow the names given in the information file refered to earlier (https://www.sciencedirect.com/science/article/pii/S2352340919306985).

##### {-}

```{r}

# Binning some numerical variables :


binning <- function(x) {
  
  #vegetables 

x$vegetables[x$vegetables <= 1] <- "Never"

x$vegetables[x$vegetables > 1 & x$vegetables <=2] <- "Sometimes"

x$vegetables[x$vegetables > 2 & x$vegetables <=3] <- "Always"


#main_meals

x$main_meals[x$main_meals >= 1 & x$main_meals < 3] <- "Btw_1_&_2"

x$main_meals[x$main_meals == 3] <- "Three"

x$main_meals[x$main_meals > 3 & x$main_meals <= 4] <- "More_than_3"


#tech_devices

x$tech_devices[x$tech_devices >= 0 & x$tech_devices <= 0.5] <- "0_hours"

x$tech_devices[x$tech_devices >= 0.5 & x$tech_devices <= 1.5] <- "1_hour"

x$tech_devices[x$tech_devices > 1.5 ] <- "2_hours_or_more"


#physical_act

x$physical_act[x$physical_act < 1] <- "I do not have"

x$physical_act[x$physical_act >= 1 & x$physical_act <= 2] <- "1 or 2 days"

x$physical_act[x$physical_act >= 2 & x$physical_act <= 4] <- "2 or 4 days"

x$physical_act[x$physical_act >= 4 & x$physical_act <= 5] <- "4 or 5 days"


#CH2O

x$CH2O[x$CH2O <= 1 ] <- "Less than a liter"

x$CH2O[x$CH2O <= 2 ] <- "Between 1 and 2 L"

x$CH2O[x$CH2O <=3 ] <- "More than 2 L"

return(x)  
  
}

obesity_bin = binning(obesity)


```

##### {-}

##### As we saw with the `str()` function, all the categorical variables are treated as `character`.

##### Therefore, we will now convert all the categorical variables to `factor` type.

##### {-}

```{r}

# Converting character variables to factor :


to_factor <- function(x) {
  
x$Gender = as.factor(x$Gender)
x$family_history = as.factor(x$family_history)
x$eat_caloric = as.factor(x$eat_caloric)
x$food_inbetween = as.factor(x$food_inbetween)
x$SMOKE = as.factor(x$SMOKE)
x$monitor_cal = as.factor(x$monitor_cal)
x$alcohol = as.factor(x$alcohol)
x$MTRANS = as.factor(x$MTRANS)
x$NObeyesdad = as.factor(x$NObeyesdad)
x$vegetables = as.factor(x$vegetables)
x$main_meals= as.factor(x$main_meals)
x$CH2O= as.factor(x$CH2O)
x$physical_act= as.factor(x$physical_act)
x$tech_devices= as.factor(x$tech_devices)

return(x)

}

obesity_bin = to_factor(obesity)

```

##### {-}

##### Let's now remove any missing values.

##### {-}

```{r}

# Checking if there are Missing Values :

sum(is.na(obesity))

```

##### {-}

##### There are no missing values within our dataset! So there is no need to remove any NA.

##### {-}


# Exploratory Data Analysis

##### {-}

```{r}

ggplot(data=obesity, aes(x=NObeyesdad)) + 
  geom_bar(aes(y = ..prop.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

##### {-}

##### We see that the distribution of observations across the different weights is quite uniform, meaning that we do not have an unbalanced data set with respect to our variable of interest (the weight).

##### Let's now look at some histograms for all the continuous variables in our dataset.

##### {-}

```{r}

# Creating histograms :

multi.hist(obesity[,2:4], density = TRUE)

# Creating boxplots :

par(mfrow = c(1, 3))

boxplot(obesity$Weight, ylab = "Weight")
boxplot(obesity$Height, ylab = "Height")
boxplot(obesity$Age, ylab = "Age")


#We may have ONE outlier for Weight, and almost one for Height!
#Age is VERY right skewed!
```

##### {-}

#Interpretation:

...



##### Now, let's do some barplots in order to get an idea of the distribution of each of the categorical variables.

##### {-}

```{r}

# Barplots :

plot_1 = ggplot(data=obesity, aes(x=NObeyesdad)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_2 = ggplot(data=obesity, aes(x=main_meals)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_3 = ggplot(data=obesity, aes(x=Gender)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_4 = ggplot(data=obesity, aes(x=family_history)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_5 = ggplot(data=obesity, aes(x=vegetables)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_6 = ggplot(data=obesity, aes(x=food_inbetween)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_7 = ggplot(data=obesity, aes(x=tech_devices)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_8 = ggplot(data=obesity, aes(x=eat_caloric)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_9 = ggplot(data=obesity, aes(x=SMOKE)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_10 = ggplot(data=obesity, aes(x=CH2O)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_11 = ggplot(data=obesity, aes(x=monitor_cal)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_12 = ggplot(data=obesity, aes(x=physical_act)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_13 = ggplot(data=obesity, aes(x=alcohol)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)

plot_14 = ggplot(data=obesity, aes(x=MTRANS)) + 
  geom_bar(aes(y = ..count.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)


# Arranging them two-by-two :

grid.arrange(plot_1, plot_2, ncol=2)
grid.arrange(plot_3, plot_4, ncol=2)
grid.arrange(plot_5, plot_6, ncol=2)
grid.arrange(plot_7, plot_8, ncol=2)
grid.arrange(plot_9, plot_10, ncol=2)
grid.arrange(plot_11, plot_12, ncol=2)
grid.arrange(plot_13, plot_14, ncol=2)

```

##### {-}

##### Let's look at the correlations between the variables.

##### {-}

```{r}

# Correlation plot

cor.plot(na.omit(obesity [c(2,3,4)]))

```

##### {-}

##### And now we dummify all the categorical and binary variables, in order to make them "ready" for the subsequent data analysis!

##### {-}

```{r message=FALSE, warning=FALSE}


# Dummyfing the binary variables(family_history, eat_caloric, SMOKE, and monitor_cal) :

# Gender 1 = female, 0 = male
obesity_dummy <- cbind(dummy(obesity$Gender, sep = "_"), obesity[2:17])
names(obesity_dummy)[1] <- c("Gender")
obesity_dummy <- subset(obesity_dummy, select = -c(2) )


# family_history 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:4], dummy(obesity_dummy$family_hist, sep = "_"), obesity_dummy[6:17])
names(obesity_dummy)[6] <- c("family_hist")
obesity_dummy <- subset(obesity_dummy, select = -c(5) )


# eat_caloric with 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:5], dummy(obesity_dummy$eat_caloric, sep = "_"), obesity_dummy[7:17])
names(obesity_dummy)[7] <- c("eat_caloric")
obesity_dummy <- subset(obesity_dummy, select = -c(6) )


# SMOKE 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:9], dummy(obesity_dummy$SMOKE, sep = "_"), obesity_dummy[11:17])
names(obesity_dummy)[11] <- c("smoke")
obesity_dummy <- subset(obesity_dummy, select = -c(10) )


# monitor_cal 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:11], dummy(obesity_dummy$monitor_cal, sep = "_"), obesity_dummy[13:17])
names(obesity_dummy)[13] <- c("monitor_cal")
obesity_dummy <- subset(obesity_dummy, select = -c(12) )



# Dummmyfying the categorical variables

# vegetables 
obesity_dum <- cbind( obesity_dummy[1:6], dummy(obesity_dummy$vegetables, sep = "_"), obesity_dummy[8:17])
names(obesity_dum)[7:9] <- c("vegetables_never","vegetables_sometimes","vegetables_always")

# main_meals
obesity_dum <- cbind( obesity_dum[1:9], dummy(obesity_dum$main_meals, sep = "_"), obesity_dum[11:19])
names(obesity_dum)[10:12] <- c("main_meals_Btw_1_2","main_meals_More_than_3","main_meals_three")

# food_in_between
obesity_dum <- cbind( obesity_dum[1:12], dummy(obesity_dum$food_inbetween, sep = "_"), obesity_dum[14:21])
names(obesity_dum)[13:16] <- c("food_inbetween_always","food_inbetween_frequently","food_inbetween_no", "food_inbetween_sometimes")

# alcohol
obesity_dum <- cbind( obesity_dum[1:21], dummy(obesity_dum$alcohol, sep = "_"), obesity_dum[23:24])
names(obesity_dum)[22:25] <- c("alcohol_always","alcohol_frequently","alcohol_no", "alcohol_sometimes")

# MTRANS
obesity_dum <- cbind( obesity_dum[1:25], dummy(obesity_dum$MTRANS, sep = "_"), obesity_dum[27])
names(obesity_dum)[26:30] <- c("mtrans_automobile","mtrans_bike","mtrans_motorbike", "mtrans_public_transportation", "mtrans_walking")

# CH2O
obesity_dum <- cbind( obesity_dum[1:17], dummy(obesity_dum$CH2O, sep = "_"), obesity_dum[19:31])
names(obesity_dum)[18:20] <- c("CH2O_less_than_a_liter","CH2O_between_1_and_2","CH2O_more_than_2")

# physical_act
obesity_dum <- cbind( obesity_dum[1:21], dummy(obesity_dum$physical_act, sep = "_"), obesity_dum[23:33])
names(obesity_dum)[22:24] <- c("physical_act_do_not_have","physical_act_1_2","physical_act_2_4")


# tech_devices : this one is a little bit tricky since there a many categories but only one is represented within the data!

obesity_dum <- cbind( obesity_dum[1:24], dummy(obesity_dum$tech_devices, sep = "_"), obesity_dum[26:35])
names(obesity_dum)[25] <- c("tech_devices_0_2")

# NObeyesdad
obesity_dum <- cbind( obesity_dum[1:34], dummy(obesity_dum$NObeyesdad, sep = "_"))
names(obesity_dum)[35:41] <- c("insufficient_weight", "normal_weight", "obesity_type_1", "obesity_type_2", "obesity_type_3", "overweight_level_1", "overweight_level_2")

```





# Data Analysis

## Multiple Linear Regression

##### {-}

```{r}

obesity_lm_dum <- subset(obesity_dum, select = c(1:34))

# Linear regression
#formula: Weight = Gender, Age, Height, 
lm_weight <- lm(Weight ~ Gender + Age + Height + family_hist + eat_caloric + vegetables_sometimes +vegetables_always + main_meals_Btw_1_2 + main_meals_More_than_3 + food_inbetween_always + food_inbetween_frequently + food_inbetween_sometimes + smoke + CH2O_between_1_and_2 + CH2O_more_than_2 + monitor_cal + physical_act_1_2 +physical_act_2_4 + tech_devices_0_2 + alcohol_always + alcohol_frequently + alcohol_sometimes + mtrans_automobile + mtrans_bike + mtrans_public_transportation  , data = train.set)

summary(lm_weight)
plot(lm_weight)



```

```{r}
#Stepwise model selection

#Forward
lm_forward_obesity <- step(lm_weight, direction = "forward")
summary(lm_forward_obesity)
#AIC: 7008.02

#Backward
lm_backward_obesity <- step(lm_weight, direction = "backward")
summary(lm_backward_obesity)
#AIC: 6996.87

#Both
lm_both_obesity <- step(lm_weight, direction = "both")
summary(lm_both_obesity)
#AIC: 6996.87

#Add comments +Assumptions
```

```{r}
#Predictions on the validation set

#Forward model:
forward_pred_obesity <- predict(lm_forward_obesity, valid.set)

#RMSE
gofRMSE(valid.set$Weight, forward_pred_obesity, dgt = 3) #16.525
#Mean error
gofME(valid.set$Weight, forward_pred_obesity, dgt = 3) #0.977
#MAPE
gofMAPE(valid.set$Weight, forward_pred_obesity, dgt = 3)#16.485


#Backward model:
backward_pred_obesity <- predict(lm_backward_obesity, valid.set)

#RMSE
gofRMSE(valid.set$Weight, backward_pred_obesity, dgt = 3) #16.565
#Mean error
gofME(valid.set$Weight, backward_pred_obesity, dgt = 3) #0.949
#MAPE
gofMAPE(valid.set$Weight, backward_pred_obesity, dgt = 3)#16.533


#Both model:
both_pred_obesity <- predict(lm_both_obesity, valid.set)

#RMSE
gofRMSE(valid.set$Weight, both_pred_obesity, dgt = 3) #16.565
#Mean error
gofME(valid.set$Weight, both_pred_obesity, dgt = 3) #0.949
#MAPE
gofMAPE(valid.set$Weight, both_pred_obesity, dgt = 3)#16.533

#Add comments +Assumptions


```




##### {-}








## k-Nearest Neighbors

##### Before continuing with the analysis, a data partitioning is necessary.

##### Because the dataset is not very large (only 2111 observations), we judge it better to only proceed with partitioning into training and validation sets. However, better results would be obtained if we keep a third "test set".

```{r}

# Partitioning the data (60% training, 40% validation)

set.seed(1)

train.obs <- sample(rownames(obesity_dum), dim(obesity_dum)[1]*0.6)
train.set <- obesity_dum[train.obs, ]  

set.seed(1)
 
valid.obs <- setdiff(rownames(obesity_dum), train.obs)
valid.set <- obesity_dum[valid.obs, ]

```

##### {-}

##### But first of all, we should normalize the data, since we have different scales and big values can dominate small values! We normalize only the numerical data.

```{r}

# Normalizing the data :

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

train.set.norm <- as.data.frame(lapply(train.set[, c(2:4)], normalize))

valid.set.norm <- as.data.frame(lapply(valid.set[, c(2:4)], normalize))


# Regrouping into final dataset, with replacement of non-normalized variables :

train.final <- cbind(train.set.norm, train.set[, c(1, 5:41)])

valid.final <- cbind(valid.set.norm, valid.set[, c(1, 5:41)])

```

##### {-}

```{r}

denormalize <- function(x, y) {
  
  return ((x*(max(y) - min(y))) + min(y))
  
}


# Running the model to look for different values of RMSE :

rmse.df = data.frame(k = seq(1, 40, 1), RMSE = rep(0, 40))


set.seed(1)

for(i in 1:40){
  
  knn.pred = knn(
    train = train.final[, -3],
    test = valid.final[, -3],
    cl = train.final[, 3],
    k = i
  )
  
  k_nn = as.numeric(as.character(knn.pred))
  
  predicted = denormalize(k_nn, valid.set[, 4])
  
  rmse.df[i, 2] = sqrt(mean((predicted-valid.set[, 4])^2))
}


pander(rmse.df)

plot(rmse.df$k, rmse.df$RMSE, xlab = "# of Neighbors", ylab = "RMSE", main = "Selecting the best 'k'")



# Best is k = 1, so :

set.seed(1)

k_nn <-
  knn(
    train = train.final[, -3],
    test = valid.final[, -3],
    cl = train.final[, 3],
    k = 1
  )

k_nn = as.numeric(as.character(k_nn))

predicted = denormalize(k_nn, valid.set[, 4])


RMSE = sqrt(mean((predicted-valid.set[, 4])^2))

RMSE



```

#Weird! If we change the set.seed, the results for RMSE change!! So, which set.seed to choose?


##### {-}

## Regression Tree

```{r}

set.seed(1)


# First run a quite big tree (CP = 0.00001) :

tree_1 <- rpart(
   Weight ~ .,
   data = train.set,
   method = "anova",
   control = rpart.control(
      cp = 0.00001,
      minbucket = 1,
      maxdepth = 10
   )
)


# We do a CV : must locate in the table the point from which the CV error starts to rise :

printcp(tree_1)

# In this case, it starts to rise when CP = 0.00032252
# BUT, there is a standard error in that point estimate! If we do 0.023867 + 0.0016730 = 0.02554

# So, we can go for a SMALLER tree with 28 splits instead of 32, which corresponds to a CP of 0.00056494

set.seed(1)

tree_2 <- rpart(
   Weight ~ .,
   data = train.set,
   method = "anova",
   control = rpart.control(
      cp = 0.00056494,
      minbucket = 1,
      maxdepth = 10
   )
)

plot_tree = prp(
   tree_2,
   type = 1,
   extra = 1,
   under = TRUE,
   split.font = 1,
   varlen = -10
)







# Let's compare the RMSE for validation and training sets :

# First, let's create two vectors, one for the predicted values, and another for the actual values :

predicted_train <- predict(tree_2, train.set)
actual_train <- train.set$Weight

# And lastly, we make use of the RSME formula to calculate it :

RMSE_train = sqrt(mean((predicted_train-actual_train)^2))

RMSE_train

# Same but for the validation set :

predicted_valid <- predict(tree_2, valid.set)
actual_valid <- valid.set$Weight


RMSE_valid = sqrt(mean((predicted_valid-actual_valid)^2))

RMSE_valid

# It is very normal that RMSE is smaller with the training data, because we have selected the optimal CP according to the training data. However, the difference seems not so big. Let's look at some boxplots to compare the performance of the tree on both sets (training and validation) :

par(mfrow = c(1, 2))

boxplot(
   predicted_train,
   actual_train,
   names = c("Predicted", "Actual"),
   ylab = "Weight",
   xlab = "Training Set"
)

boxplot(
   predicted_valid,
   actual_valid,
   names = c("Predicted", "Actual"),
   ylab = "Weight",
   xlab = "Validation Set"
)


# Clearly, the validation set seems to have done a better job! Probably the higer RMSE is due to the presence of an outlier in the validation set!

# So we can leave the CP as it is, and the tree will grow until 28 splits.



# INTERESTING : comparison of both KNN and regression tree on validation set

plot(predicted-predicted_valid)+
  abline(h = 5)+
  abline(h = -5)


# They seem to behave almost equally at the beginning, but then there is an upward shift, meaning that some considerable differences are ocurring. Let's take a more precise look at each method compared with the validation data :

par(mfrow = c(1, 2))

# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual (= error)") +
  abline(h = mean(predicted-valid.set[,4]))


# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual (= error)") +
  abline(h = mean(predicted_valid-valid.set[, 4]))


# As suggested by the aforementioned graph, towards the end the k-NN is separating itself from its trend around 0.

# VERY INTERESTING! Actually we can see the trade-off between BIAS and VARIANCE. Certainly, the k-NN seems to be more precise (less variance), since the points are less far apart from each other. BUT, we observe an upward trend! So there is an upward bias towards to end. However, the regression tree has a lot of variance, BUT on average it is very precise (around zero). Indeed :

mean(predicted-valid.set[,4]) 

mean(predicted_valid-valid.set[, 4])

# For the regression tree, the mean is very close to zero.

# But what do we want here? Do we want a very accurate prediction although it may be around on average 4 Kg away from the truth? Or do we want a prediction which is very far from the truth but, taking into account all predictions, on average we are almost exactly on the target?

# Probably we want something like the k-NN, since 4 Kg is not much.

# The regression tree is less biased, more certainly the amount of error is very big (the differences predicted - actual are quite big). 

# Therefore, we may try to do some BOOSTING trees, in order to really focus on the missclassified observations, and after that we will COMPARE AGAIN like we just did with the k-NN. Probably there will be less variance around 0 for the errors.

```


##### {-}

## Ensemble Method (k-NN + Regression Tree)

##### The aim of this ensemble method is to combine both k-NN and Regression Tree in order to obtain even better results. This combination of methods will be done by taking the average prediction of the variable of interest (`Weight`).

##### This means that the predicted weight using this ensemble method will be obtained by running both combined methods and then taking the average over both results.

```{r}

# Creating dataframe :

my_df <-
  data.frame(
    actual = valid.set[, 4],
    knn = predicted,
    Regression_tree = predicted_valid,
    Ensemble_Method = (predicted + predicted_valid) / 2
  )

```


##### {-}


```{r}

# Creating a person for prediction :

example.df = obesity[1,]

example.df$Gender = "Male"
example.df$Age = 25
example.df$Height = 1.78
example.df$Weight = 70.0
example.df$family_history = "no"
example.df$eat_caloric = "no"
example.df$vegetables = "Always"
example.df$main_meals = "More_than_3"
example.df$food_inbetween = "no"
example.df$SMOKE = "no"
example.df$CH2O = "Between 1 and 2 L"
example.df$monitor_cal = "no"
example.df$physical_act = "2 or 4 days"
example.df$tech_devices = "0-2_hours"
example.df$alcohol = "no"
example.df$MTRANS = "Walking"
example.df$NObeyesdad = "Normal_weight"


norm.values <- preProcess(obesity[, c(2:4)], method = "range")

example.norm <- predict(norm.values, example.df)


example.df = to_factor(example.df)

#example.df = dummy(example.df)   Create a SINGLE function for dummyfication (need to eliminate the _dummy dataset)

#predict(k_nn, example.df)
#predict(tree_2, example.df)
#...

#for Multiple Linear Regression, simply replace coefficients and variable values into the formula to get the predicted weight. Maybe create a function called "MLR()" for this!



```



##### {-}