---
title: "Data Mining Project (MaBAn 2020)"
subtitle: "Predicting obesity levels according to daily habits"

author: "by : Ángel Tomás-Ripoll & Laurence Tréteault-Falsafi"

output:
  pdf_document:
    toc: true
    
urlcolor: blue
geometry: "left=2.5cm,right=2.5cm,top=1cm,bottom=2.5cm"
  
---

# Introduction

##### For this project, our objective is to predict the expected weight level (in Kg) for a given person depending on certain daily habits (eating and physical activity) and on the person's age, gender and height. 

##### To do this, we found a quite interesting dataset (click here : http://archive.ics.uci.edu/ml/datasets/Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+) containing 2111 observations and 17 variables (mainly categorical). 

##### Please, find here a manually created metadata table :

##### {-}

```{r}

# To adjust the page margins when knitting to PDF :

library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=45),tidy=TRUE)

```


```{r message=FALSE, warning=FALSE}

# Used packages :
library(pander)
library(dplyr)
library(gt)
library(car)
library(ggplot2)
source("VIF.R")

# Working Directory :
setwd("~/GitHub/CVTDM_Project_MaBAn_2020")


# Reading the data :
obesity <- read.csv("Obesity.csv", header=T, sep=",")
attach(obesity)



# Small metadata table :

tibble_table <- 
  tibble(
    "Variable Name" = c(colnames(obesity)[1:14], "", colnames(obesity)[15:17]),
    Description = c("Gender", "Age", "Height", "Weight", "Has a family member suffered or suffers from overweight?", "Do you eat high caloric food frequently?", "Do you usually eat vegetables in your meals?", "How many main meals do you have daily?", "Do you eat any food between meals?", "Do you smoke?", "How much water do you drink daily?", "Do you monitor the calories you eat daily?", "How often do you have physical activity?", "How much time do you use technological devices such as", "cell phone videogames, television, computer and others?", "How often do you drink alcohol?", "Which transportation do you usually use?", "Obesity level based on calculation of Mass Body Index")
  )

metadata <- gt(data = tibble_table)

metadata %>%
  tab_header(title = md("**Metadata**"),
             subtitle = "from the dataset we are using") %>%
  
  tab_source_note(source_note = "Based on information in : 
                  
  https://www.sciencedirect.com/science/article/pii/S2352340919306985")

```

##### {-}
##### {-}

##### Here is a small overview of the first observations :

##### {-}

```{r}

pander(head(obesity))

```

##### The variable of interest is the fourth one, the "Weight", so it will be our dependent variable.

##### We were "lucky" on the fact that this dataset has a quite high level of quality, because it has no missing observations, and our subsequent exploratory analysis will tell us if there are outliers to be handled with.


##### Once we are done with a Data Exploratory Analysis and with a proper Data Pre-Processing, we will develop several models in order to accurately predict the level of weight of each individual.

##### The models will be :

1. **Multiple Linear Regression** (not ANOVA since "Age" and "Height" are numerical)
2. **Classification tree** (complemented with a random forest / boosted trees / bagged trees)
3. **k-Nearest Neighbors**
4. **Ensemble Method**

##### We will deploy the best model based on error metrics and prediction performance.

##### At the very end, we will make a **Shiny App** available, in which any user can fill-in a questionnaire concerning daily habits, age and height. Then, the App will tell the user what is the expected weight according to those characteristics, and will present the result in two forms :

* The expected weight in Kg.

* The expected obesity level based on the Body Mass Index, following the classification comming from the World Health Organisation.

##### The user will also be able to **select the type of model** that will predict the results. That way, it will be interesting to see with just a few clicks how each model will yield different results.

##### {-}

# Data Pre-Processing




##### {-}

```{r}

ggplot(data=obesity, aes(x=NObeyesdad)) + 
  geom_bar(aes(y = ..prop.., group = 1)) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

##### {-}

##### We see that the distribution of observations across the different weights is quite uniform, meaning that we do not have an unbalanced data set with respect to our variable of interest (the weight).

##### Let's now look at some histograms for all the continuous variables in our dataset.

##### {-}

```{r}

pander(summary(obesity))
str(obesity)

for (i in 2:4) {
  hist(
    obesity[, i],
    breaks = 10,
    main = names(obesity[i]),
    xlab = "value",
    freq = T
  )
  abline(v = mean(obesity[, i]),
         col = 1,
         lwd = 2)
  abline(v = median(obesity[, i]),
         col = 2,
         lwd = 2)
  legend(
    "topright",
    legend = c("mean", "median"),
    col = c("black", "red"),
    lty = 1
  )
}
```

##### {-}

##### Now, to have an idea of the distribution of the categorical variables, we will first replace the numbers with a string corresponding to its category, and then implement a `for` loop to get the frequencies.

##### {-}

```{r}

obesity$FCVC[obesity$FCVC <= 1] <- 'Never'

obesity$FCVC[obesity$FCVC > 1 & obesity$FCVC <=2] <- "Sometimes"

obesity$FCVC[obesity$FCVC > 2 & obesity$FCVC <=3] <- "Always"



for (i in c(1, 5:10, 12, 15:17)){
  x = count(obesity, obesity[, i], name = "Count")
  colnames(x)[1] = colnames(obesity[i])
 
  
}

summary(as.factor(family_history_with_overweight))
```




