plot_14 = ggplot(data=obesity, aes(x=MTRANS)) +
geom_bar(aes(y = ..count.., group = 1)) +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
geom_text(stat='count', aes(label=..count..), vjust=-0.5, size=2.2)
# Arranging them two-by-two :
grid.arrange(plot_1, plot_2, ncol=2)
grid.arrange(plot_3, plot_4, ncol=2)
grid.arrange(plot_5, plot_6, ncol=2)
grid.arrange(plot_7, plot_8, ncol=2)
grid.arrange(plot_9, plot_10, ncol=2)
grid.arrange(plot_11, plot_12, ncol=2)
grid.arrange(plot_13, plot_14, ncol=2)
# Correlation plot
cor.plot(na.omit(obesity [c(2,3,4)]))
# Dummyfing the binary variables(family_history, eat_caloric, SMOKE, and monitor_cal) :
# Gender 1 = female, 0 = male
obesity_dummy <- cbind(dummy(obesity$Gender, sep = "_"), obesity[2:17])
names(obesity_dummy)[1] <- c("Gender")
obesity_dummy <- subset(obesity_dummy, select = -c(2) )
# family_history 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:4], dummy(obesity_dummy$family_hist, sep = "_"), obesity_dummy[6:17])
names(obesity_dummy)[6] <- c("family_hist")
obesity_dummy <- subset(obesity_dummy, select = -c(5) )
# eat_caloric with 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:5], dummy(obesity_dummy$eat_caloric, sep = "_"), obesity_dummy[7:17])
names(obesity_dummy)[7] <- c("eat_caloric")
obesity_dummy <- subset(obesity_dummy, select = -c(6) )
# SMOKE 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:9], dummy(obesity_dummy$SMOKE, sep = "_"), obesity_dummy[11:17])
names(obesity_dummy)[11] <- c("smoke")
obesity_dummy <- subset(obesity_dummy, select = -c(10) )
# monitor_cal 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:11], dummy(obesity_dummy$monitor_cal, sep = "_"), obesity_dummy[13:17])
names(obesity_dummy)[13] <- c("monitor_cal")
obesity_dummy <- subset(obesity_dummy, select = -c(12) )
# Dummmyfying the categorical variables
# vegetables
obesity_dum <- cbind( obesity_dummy[1:6], dummy(obesity_dummy$vegetables, sep = "_"), obesity_dummy[8:17])
names(obesity_dum)[7:9] <- c("vegetables_never","vegetables_sometimes","vegetable_always")
# main_meals
obesity_dum <- cbind( obesity_dum[1:9], dummy(obesity_dum$main_meals, sep = "_"), obesity_dum[11:19])
names(obesity_dum)[10:12] <- c("main_meals_Btw_1_&_2","main_meals_More_than_3","main_meals_three")
# food_in_between
obesity_dum <- cbind( obesity_dum[1:12], dummy(obesity_dum$food_inbetween, sep = "_"), obesity_dum[14:21])
names(obesity_dum)[13:16] <- c("food_inbetween_always","food_inbetween_frequently","food_inbetween_no", "food_inbetween_sometimes")
# alcohol
obesity_dum <- cbind( obesity_dum[1:21], dummy(obesity_dum$alcohol, sep = "_"), obesity_dum[23:24])
names(obesity_dum)[22:25] <- c("alcohol_always","alcohol_frequently","alcohol_no", "alcohol_sometimes")
# MTRANS
obesity_dum <- cbind( obesity_dum[1:25], dummy(obesity_dum$MTRANS, sep = "_"), obesity_dum[27])
names(obesity_dum)[26:30] <- c("mtrans_automobile","mtrans_bike","mtrans_motorbike", "mtrans_public_transportation", "mtrans_walking")
# CH2O
obesity_dum <- cbind( obesity_dum[1:17], dummy(obesity_dum$CH2O, sep = "_"), obesity_dum[19:31])
names(obesity_dum)[18:20] <- c("CH2O_less_than_a_liter","CH2O_between_1_and_2","CH2O_more_than_2")
# physical_act
obesity_dum <- cbind( obesity_dum[1:21], dummy(obesity_dum$physical_act, sep = "_"), obesity_dum[23:33])
names(obesity_dum)[22:24] <- c("physical_act_do_not_have","physical_act_1_2","physical_act_2_4")
# tech_devices : this one is a little bit tricky since there a many categories but only one is represented within the data!
obesity_dum <- cbind( obesity_dum[1:24], dummy(obesity_dum$tech_devices, sep = "_"), obesity_dum[26:35])
names(obesity_dum)[25] <- c("tech_devices_0_2")
# NObeyesdad
obesity_dum <- cbind( obesity_dum[1:34], dummy(obesity_dum$NObeyesdad, sep = "_"))
names(obesity_dum)[35:41] <- c("insufficient_weight", "normal_weight", "obesity_type_1", "obesity_type_2", "obesity_type_3", "overweight_level_1", "overweight_level_2")
obesity_lm_dum <- subset(obesity_dum, select = c(1:34))
# Linear regression
lm_weight <- lm(Weight ~., data = obesity_lm_dum)
summary(lm_weight)
plot(lm_weight)
# Partitioning the data (60% training, 40% validation)
set.seed(1)
train.obs <- sample(rownames(obesity_dum), dim(obesity_dum)[1]*0.6)
train.set <- obesity_dum[train.obs, ]
set.seed(1)
valid.obs <- setdiff(rownames(obesity_dum), train.obs)
valid.set <- obesity_dum[valid.obs, ]
# Normalizing the data :
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train.set.norm <- as.data.frame(lapply(train.set[, c(2:4)], normalize))
valid.set.norm <- as.data.frame(lapply(valid.set[, c(2:4)], normalize))
# Regrouping into final dataset, with replacement of non-normalized variables :
train.final <- cbind(train.set.norm, train.set[, c(1, 5:41)])
valid.final <- cbind(valid.set.norm, valid.set[, c(1, 5:41)])
denormalize <- function(x, y) {
return ((x*(max(y) - min(y))) + min(y))
}
# Running the model to look for different values of RMSE :
rmse.df = data.frame(k = seq(1, 40, 1), RMSE = rep(0, 40))
set.seed(1)
for(i in 1:40){
knn.pred = knn(
train = train.final[, -3],
test = valid.final[, -3],
cl = train.final[, 3],
k = i
)
k_nn = as.numeric(as.character(knn.pred))
predicted = denormalize(k_nn, valid.set[, 4])
rmse.df[i, 2] = sqrt(mean((predicted-valid.set[, 4])^2))
}
pander(rmse.df)
plot(rmse.df$k, rmse.df$RMSE, xlab = "# of Neighbors", ylab = "RMSE", main = "Selecting the best 'k'")
# Best is k = 1, so :
set.seed(1)
k_nn <-
knn(
train = train.final[, -3],
test = valid.final[, -3],
cl = train.final[, 3],
k = 1
)
k_nn = as.numeric(as.character(k_nn))
predicted = denormalize(k_nn, valid.set[, 4])
RMSE = sqrt(mean((predicted-valid.set[, 4])^2))
RMSE
# Creating a person for prediction :
example.df = obesity[1,]
example.df$Gender = "Male"
example.df$Age = 25
example.df$Height = 1.78
example.df$Weight = 70.0
example.df$family_history = "no"
example.df$eat_caloric = "no"
example.df$vegetables = "Always"
example.df$main_meals = "More_than_3"
example.df$food_inbetween = "no"
example.df$SMOKE = "no"
example.df$CH2O = "Between 1 and 2 L"
example.df$monitor_cal = "no"
example.df$physical_act = "2 or 4 days"
example.df$tech_devices = "0-2_hours"
example.df$alcohol = "no"
example.df$MTRANS = "Walking"
example.df$NObeyesdad = "Normal_weight"
norm.values <- preProcess(obesity[, c(2:4)], method = "range")
example.norm <- predict(norm.values, example.df)
example.df = to_factor(example.df)
example.df
rmse.df
?rpart
tree <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.001,
minbucket = 1,
maxdepth = 30
)
)
printcp(tree)
plot_tree = prp(
tree,
type = 1,
extra = 1,
under = TRUE,
split.font = 1,
varlen = -10
)
printcp(tree)
tree <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0,
minbucket = 1,
maxdepth = 30
)
)
printcp(tree)
printcp(tree)
plot_tree = prp(
tree,
type = 1,
extra = 1,
under = TRUE,
split.font = 1,
varlen = -10
)
printcp(tree)
tree <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.001,
minbucket = 1,
maxdepth = 30
)
)
printcp(tree)
tree <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.001,
minbucket = 1,
maxdepth = 10
)
)
printcp(tree)
tree <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00001,
minbucket = 1,
maxdepth = 10
)
)
printcp(tree)
table = printcp(tree)
?printcp
printcp(tree)$xerror
printcp(tree)@xerror
set.seed(1)
tree <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00001,
minbucket = 1,
maxdepth = 10
)
)
printcp(tree)
plot_tree = prp(
tree,
type = 1,
extra = 1,
under = TRUE,
split.font = 1,
varlen = -10
)
printcp(tree)
tree_2 <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00032252,
minbucket = 1,
maxdepth = 10
)
)
plot_tree = prp(
tree_2,
type = 1,
extra = 1,
under = TRUE,
split.font = 1,
varlen = -10
)
printcp(tree)
tree_2 <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00056494,
minbucket = 1,
maxdepth = 10
)
)
plot_tree = prp(
tree_2,
type = 1,
extra = 1,
under = TRUE,
split.font = 1,
varlen = -10
)
predicted_train <- predict(tree_2, train.set)
actual_train <- train.set$Weight
RMSE_train = sqrt(mean((predicted_train-actual_train)^2))
RMSE_train
predicted_valid <- predict(tree_2, valid.set)
actual_valid <- valid.set$Weight
RMSE_valid = sqrt(mean((predicted_valid-actual_valid)^2))
RMSE_valid
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Price",
xlab = "Training Data"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Price",
xlab = "Validation Data"
)
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Data"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Data"
)
boxplot(obesity$Weight)
boxplot(obesity$Height, ylab = "Height")
boxplot(obesity$Age, ylab = "Age")
par(mfrow = c(1, 3))
boxplot(obesity$Weight, ylab = "Weight")
boxplot(obesity$Height, ylab = "Height")
boxplot(obesity$Age, ylab = "Age")
RMSE_train
RMSE_valid
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Data"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Data"
)
set.seed(1)
tree_2 <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00056494,
minbucket = 1,
maxdepth = 10
)
)
predicted_train <- predict(tree_2, train.set)
actual_train <- train.set$Weight
RMSE_train = sqrt(mean((predicted_train-actual_train)^2))
RMSE_train
predicted_valid <- predict(tree_2, valid.set)
actual_valid <- valid.set$Weight
RMSE_valid = sqrt(mean((predicted_valid-actual_valid)^2))
RMSE_valid
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Data"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Data"
)
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Set"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Set"
par(mfrow = c(1, 2))
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Set"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Set"
)
predicted_valid
predicted
predicted
plot(predicted)
plot(predicted-predicted_valid)
plot(predicted-predicted_valid)+
abline(h = 5)+
abline(h = -5)
View(train.set)
predicted_knn_train = denormalize(predict(knn.pred, train.final), train.set[, 4])
predicted_knn_train = denormalize(predict(k_nn, train.final), train.set[, 4])
pred_knn_train = predict(knn.pred, train.final)
pred_knn_train = predict(k_nn, train.final)
View(train.final)
pred_knn_train = predict(k_nn, train.final[, 3])
pred_knn_train = predict(knn.pred, train.final[, 3])
k_nn
train.final[, 3]
pred_knn_train = predict(k_nn, train.final)
plot(predicted-predicted_valid)+
abline(h = 5)+
abline(h = -5)
par(mfrow = c(1, 2)) +
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Set"
) +
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Set"
)
plot(predicted-predicted_valid)+
abline(h = 5)+
abline(h = -5)
plot(predicted-valid.set[,4])
# For tree :
plot(predicted_valid-valid.set[, 4])
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Set"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Set"
)
# For KNN :
plot(predicted-valid.set[,4])
# For tree :
plot(predicted_valid-valid.set[, 4])
par(mfrow = c(2, 1))
# For KNN :
plot(predicted-valid.set[,4])
# For tree :
plot(predicted_valid-valid.set[, 4])
par(mfrow = c(1, 2))
# For KNN :
plot(predicted-valid.set[,4])
# For tree :
plot(predicted_valid-valid.set[, 4])
par(mfrow = c(1, 2))
# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual")
# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual")
mean(predicted-valid.set[,4])
mean(predicted_valid-valid.set[, 4])
# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual") +
abline(h = mean(predicted-valid.set[,4]))
# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual") +
abline(h = mean(predicted_valid-valid.set[, 4]))
par(mfrow = c(1, 2))
# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual") +
abline(h = mean(predicted-valid.set[,4]))
# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual") +
abline(h = mean(predicted_valid-valid.set[, 4]))
par(mfrow = c(1, 2))
# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual (= error)") +
abline(h = mean(predicted-valid.set[,4]))
# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual (= error)") +
abline(h = mean(predicted_valid-valid.set[, 4]))
plot(predicted-predicted_valid)+
abline(h = 5)+
abline(h = -5)
par(mfrow = c(1, 2))
# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual (= error)") +
abline(h = mean(predicted-valid.set[,4]))
# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual (= error)") +
abline(h = mean(predicted_valid-valid.set[, 4]))
