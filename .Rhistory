obesity_dummy <- cbind( obesity_dummy[1:5], dummy(obesity_dummy$eat_caloric, sep = "_"), obesity_dummy[7:17])
names(obesity_dummy)[7] <- c("eat_caloric")
obesity_dummy <- subset(obesity_dummy, select = -c(6) )
# SMOKE 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:9], dummy(obesity_dummy$SMOKE, sep = "_"), obesity_dummy[11:17])
names(obesity_dummy)[11] <- c("smoke")
obesity_dummy <- subset(obesity_dummy, select = -c(10) )
# monitor_cal 1 = yes, 0 = no
obesity_dummy <- cbind( obesity_dummy[1:11], dummy(obesity_dummy$monitor_cal, sep = "_"), obesity_dummy[13:17])
names(obesity_dummy)[13] <- c("monitor_cal")
obesity_dummy <- subset(obesity_dummy, select = -c(12) )
# Dummmyfying the categorical variables
# vegetables
obesity_dum <- cbind( obesity_dummy[1:6], dummy(obesity_dummy$vegetables, sep = "_"), obesity_dummy[8:17])
names(obesity_dum)[7:9] <- c("vegetables_never","vegetables_sometimes","vegetables_always")
# main_meals
obesity_dum <- cbind( obesity_dum[1:9], dummy(obesity_dum$main_meals, sep = "_"), obesity_dum[11:19])
names(obesity_dum)[10:12] <- c("main_meals_Btw_1_2","main_meals_More_than_3","main_meals_three")
# food_in_between
obesity_dum <- cbind( obesity_dum[1:12], dummy(obesity_dum$food_inbetween, sep = "_"), obesity_dum[14:21])
names(obesity_dum)[13:16] <- c("food_inbetween_always","food_inbetween_frequently","food_inbetween_no", "food_inbetween_sometimes")
# alcohol
obesity_dum <- cbind( obesity_dum[1:21], dummy(obesity_dum$alcohol, sep = "_"), obesity_dum[23:24])
names(obesity_dum)[22:25] <- c("alcohol_always","alcohol_frequently","alcohol_no", "alcohol_sometimes")
# MTRANS
obesity_dum <- cbind( obesity_dum[1:25], dummy(obesity_dum$MTRANS, sep = "_"), obesity_dum[27])
names(obesity_dum)[26:30] <- c("mtrans_automobile","mtrans_bike","mtrans_motorbike", "mtrans_public_transportation", "mtrans_walking")
# CH2O
obesity_dum <- cbind( obesity_dum[1:17], dummy(obesity_dum$CH2O, sep = "_"), obesity_dum[19:31])
names(obesity_dum)[18:20] <- c("CH2O_less_than_a_liter","CH2O_between_1_and_2","CH2O_more_than_2")
# physical_act
obesity_dum <- cbind( obesity_dum[1:21], dummy(obesity_dum$physical_act, sep = "_"), obesity_dum[23:33])
names(obesity_dum)[22:24] <- c("physical_act_do_not_have","physical_act_1_2","physical_act_2_4")
# tech_devices : this one is a little bit tricky since there a many categories but only one is represented within the data!
obesity_dum <- cbind( obesity_dum[1:24], dummy(obesity_dum$tech_devices, sep = "_"), obesity_dum[26:35])
names(obesity_dum)[25] <- c("tech_devices_0_2")
# NObeyesdad
obesity_dum <- cbind( obesity_dum[1:34], dummy(obesity_dum$NObeyesdad, sep = "_"))
names(obesity_dum)[35:41] <- c("insufficient_weight", "normal_weight", "obesity_type_1", "obesity_type_2", "obesity_type_3", "overweight_level_1", "overweight_level_2")
obesity_lm_dum <- subset(obesity_dum, select = c(1:34))
# Linear regression
#formula: Weight = Gender, Age, Height,
lm_weight <- lm(Weight ~ Gender + Age + Height + family_hist + eat_caloric + vegetables_sometimes +vegetables_always + main_meals_Btw_1_2 + main_meals_More_than_3 + food_inbetween_always + food_inbetween_frequently + food_inbetween_sometimes + smoke + CH2O_between_1_and_2 + CH2O_more_than_2 + monitor_cal + physical_act_1_2 +physical_act_2_4 + tech_devices_0_2 + alcohol_always + alcohol_frequently + alcohol_sometimes + mtrans_automobile + mtrans_bike + mtrans_public_transportation  , data = train.set)
set.seed(1)
train.obs <- sample(rownames(obesity_dum), dim(obesity_dum)[1]*0.6)
train.set <- obesity_dum[train.obs, ]
set.seed(1)
valid.obs <- setdiff(rownames(obesity_dum), train.obs)
valid.set <- obesity_dum[valid.obs, ]
View(train.set)
# Normalizing the data :
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train.set.norm <- as.data.frame(lapply(train.set[, c(2:4)], normalize))
valid.set.norm <- as.data.frame(lapply(valid.set[, c(2:4)], normalize))
# Regrouping into final dataset, with replacement of non-normalized variables :
train.final <- cbind(train.set.norm, train.set[, c(1, 5:41)])
valid.final <- cbind(valid.set.norm, valid.set[, c(1, 5:41)])
denormalize <- function(x, y) {
return ((x*(max(y) - min(y))) + min(y))
}
# Running the model to look for different values of RMSE :
rmse.df = data.frame(k = seq(1, 40, 1), RMSE = rep(0, 40))
set.seed(1)
for(i in 1:40){
knn.pred = knn(
train = train.final[, -3],
test = valid.final[, -3],
cl = train.final[, 3],
k = i
)
k_nn = as.numeric(as.character(knn.pred))
predicted = denormalize(k_nn, valid.set[, 4])
rmse.df[i, 2] = sqrt(mean((predicted-valid.set[, 4])^2))
}
pander(rmse.df)
plot(rmse.df$k, rmse.df$RMSE, xlab = "# of Neighbors", ylab = "RMSE", main = "Selecting the best 'k'")
# Best is k = 1, so :
set.seed(1)
k_nn <-
knn(
train = train.final[, -3],
test = valid.final[, -3],
cl = train.final[, 3],
k = 1
)
k_nn = as.numeric(as.character(k_nn))
predicted = denormalize(k_nn, valid.set[, 4])
RMSE = sqrt(mean((predicted-valid.set[, 4])^2))
RMSE
set.seed(1)
# First run a quite big tree (CP = 0.00001) :
tree_1 <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00001,
minbucket = 1,
maxdepth = 10
)
)
# We do a CV : must locate in the table the point from which the CV error starts to rise :
printcp(tree)
set.seed(1)
# First run a quite big tree (CP = 0.00001) :
tree_1 <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00001,
minbucket = 1,
maxdepth = 10
)
)
# We do a CV : must locate in the table the point from which the CV error starts to rise :
printcp(tree_1)
# In this case, it starts to rise when CP = 0.00032252
# BUT, there is a standard error in that point estimate! If we do 0.023867 + 0.0016730 = 0.02554
# So, we can go for a SMALLER tree with 28 splits instead of 32, which corresponds to a CP of 0.00056494
set.seed(1)
tree_2 <- rpart(
Weight ~ .,
data = train.set,
method = "anova",
control = rpart.control(
cp = 0.00056494,
minbucket = 1,
maxdepth = 10
)
)
plot_tree = prp(
tree_2,
type = 1,
extra = 1,
under = TRUE,
split.font = 1,
varlen = -10
)
# Let's compare the RMSE for validation and training sets :
# First, let's create two vectors, one for the predicted values, and another for the actual values :
predicted_train <- predict(tree_2, train.set)
actual_train <- train.set$Weight
# And lastly, we make use of the RSME formula to calculate it :
RMSE_train = sqrt(mean((predicted_train-actual_train)^2))
RMSE_train
# Same but for the validation set :
predicted_valid <- predict(tree_2, valid.set)
actual_valid <- valid.set$Weight
RMSE_valid = sqrt(mean((predicted_valid-actual_valid)^2))
RMSE_valid
# It is very normal that RMSE is smaller with the training data, because we have selected the optimal CP according to the training data. However, the difference seems not so big. Let's look at some boxplots to compare the performance of the tree on both sets (training and validation) :
par(mfrow = c(1, 2))
boxplot(
predicted_train,
actual_train,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Training Set"
)
boxplot(
predicted_valid,
actual_valid,
names = c("Predicted", "Actual"),
ylab = "Weight",
xlab = "Validation Set"
)
# Clearly, the validation set seems to have done a better job! Probably the higer RMSE is due to the presence of an outlier in the validation set!
# So we can leave the CP as it is, and the tree will grow until 28 splits.
# INTERESTING : comparison of both KNN and regression tree on validation set
plot(predicted-predicted_valid)+
abline(h = 5)+
abline(h = -5)
# They seem to behave almost equally at the beginning, but then there is an upward shift, meaning that some considerable differences are ocurring. Let's take a more precise look at each method compared with the validation data :
par(mfrow = c(1, 2))
# For KNN :
plot(predicted-valid.set[,4], main = "k-Nearest Neighbors", ylab = "Predicted - Actual (= error)") +
abline(h = mean(predicted-valid.set[,4]))
# For tree :
plot(predicted_valid-valid.set[, 4], main = "Regression Tree", ylab = "Predicted - Actual (= error)") +
abline(h = mean(predicted_valid-valid.set[, 4]))
# As suggested by the aforementioned graph, towards the end the k-NN is separating itself from its trend around 0.
# VERY INTERESTING! Actually we can see the trade-off between BIAS and VARIANCE. Certainly, the k-NN seems to be more precise (less variance), since the points are less far apart from each other. BUT, we observe an upward trend! So there is an upward bias towards to end. However, the regression tree has a lot of variance, BUT on average it is very precise (around zero). Indeed :
mean(predicted-valid.set[,4])
mean(predicted_valid-valid.set[, 4])
# For the regression tree, the mean is very close to zero.
# But what do we want here? Do we want a very accurate prediction although it may be around on average 4 Kg away from the truth? Or do we want a prediction which is very far from the truth but, taking into account all predictions, on average we are almost exactly on the target?
# Probably we want something like the k-NN, since 4 Kg is not much.
# The regression tree is less biased, more certainly the amount of error is very big (the differences predicted - actual are quite big).
# Therefore, we may try to do some BOOSTING trees, in order to really focus on the missclassified observations, and after that we will COMPARE AGAIN like we just did with the k-NN. Probably there will be less variance around 0 for the errors.
boosted_tree = boosting(Weight ~., data = train.set)
boosted_tree = boosting(Weight ~., data = train.set)
train.set$Weight <- as.factor(train.set$Weight)
boosted_tree = boosting(Weight ~., data = train.set)
?predict
pred_boost = predict(boosted_tree, valid.set, type = "response")
boosted_tree = boosting(Weight ~., data = train.set)
View(valid.set)
boosted_tree
pred_boost = predict(boosted_tree, valid.set, type = "response")
pred_boost
pred_boost = predict(boosted_tree, valid.set)
pred_boost
pred_boost = predict(boosted_tree, valid.set, type = "response")
pred_boost
pred_boost = predict(boosted_tree, valid.set, type = "numeric")
pred_boost
?boosting
?boosting
pred_boost
boosted_tree
pred_boost = predict(boosted_tree, valid.set)
pred_boost
library(randomForest)
RF = randomForest(Weight ~., data = train.set)
RF = randomForest(Weight ~., data = train.set, ntree = 500, mtry = 4, nodesize = 5, importance = TRUE)
pred_RF = predict(RF, valid.set)
pred_RF
RF
?randomForest
RF = randomForest(Weight ~., data = train.set, ntree = 500, mtry = 4, nodesize = 5, importance = TRUE, type = "regression")
?boosting
pred_RF = predict(RF, valid.set)
pred_RF
RF
?randomForest
install.packages(c("shiny", "shinyjs", "shinythemes"))
shiny::runApp('Weight_Predictor')
shinyApp(ui, server)
server <- function(input, output, session) {4}
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
)
server <- function(input, output, session) {4}
shinyApp(ui, server)
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
)
server <- function(input, output, session) {4}
shinyApp(ui, server)
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
)
server <- function(input, output, session) {4}
shinyApp(ui, server)
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
)
server <- function(input, output, session) {4}
shinyApp(ui, server)
library(shiny)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
server <- function(input, output) {
output$Text <- renderText({ print("Hola")
})
}
shinyApp(ui, server)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
server <- function(input, output) {
output$Text <- renderText({ print("Hola")
})
}
shinyApp(ui, server)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
sidebarLayout(
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
)
server <- function(input, output) {
output$Text <- renderText({ print("Hola")
})
}
shinyApp(ui, server)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
sidebarLayout(
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
)
server <- function(input, output) {
output$Text <- renderText({ cat("Hola")
})
}
shinyApp(ui, server)
shinyApp(ui, server)
shinyApp(ui, server)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
sidebarLayout(
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
)
server <- function(input, output) {
output$Text <- renderText({ cat("Hola")
})
}
shinyApp(ui, server)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
useShinyjs(),
shinyjs::extendShinyjs(text = "shinyjs.refresh = function() { location.reload(); }"),
titlePanel("CHAA Quizs"),
sidebarLayout(
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
)
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("CHAA Quizs"),
sidebarLayout(
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("CHAA Quizs"),
mainPanel(
radioButtons("Q1", "Q1 - Why are most plants green ?", Q1, selected = character(0)),
br(),
plotOutput("Text")
)
)
server <- function(input, output) {
output$Text <- renderText({ cat("Hola")
})
}
shinyApp(ui, server)
output$text <- renderText({ cat("Hola")
})
output$text <- renderText({ cat("Hola")
})
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("Weight Prediction"),
mainPanel(
radioButtons("Q1", "Q1 - Do you smoke ?", Q1, selected = character(0)),
br(),
span(textOutput("text"), style='color:red'),
)
)
server <- function(input, output) {
output$text <- renderText({ cat("Hola")
})
}
shinyApp(ui, server)
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("Weight Prediction"),
mainPanel(
radioButtons("Q1", "Q1 - Do you smoke ?", Q1, selected = character(0)),
br(),
span(textOutput("text"), style='color:red'),
)
)
shinyApp(ui, server)
output$text <- renderText({ cat("Hola")
})
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("Weight Prediction"),
mainPanel(
radioButtons("Q1", "Q1 - Do you smoke ?", Q1, selected = character(0)),
br(),
span(textOutput("text"), style='color:red'),
actionButton(inputId = "submit", label = "Know your score !", class="btn btn-secondary", icon = icon("child"), width = NULL),
)
)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("Weight Prediction"),
mainPanel(
radioButtons("Q1", "Q1 - Do you smoke ?", Q1, selected = character(0)),
br(),
span(textOutput("text"), style='color:red'),
actionButton(inputId = "submit", label = "Know your score !", class="btn btn-secondary", icon = icon("child"), width = NULL),
)
)
server <- function(input, output) {
observeEvent(input$submit, {
output$text <- renderText({ cat("Hola")
})
}
)
}
shinyApp(ui, server)
games1 <- switch(input$Q1,
"Yes" = "I am quite disappointed...",
"No" = "That's very good!",
)
library(shinyjs)
library(shinythemes)
library(shiny)
Q1 <- c("Yes", "No")
ui <- fluidPage(theme = shinytheme("flatly"),
titlePanel("Weight Prediction"),
mainPanel(
radioButtons("Q1", "Q1 - Do you smoke ?", Q1, selected = character(0)),
br(),
span(textOutput("text"), style='color:red'),
actionButton(inputId = "submit", label = "Know your score !", class="btn btn-secondary", icon = icon("child"), width = NULL),
)
)
server <- function(input, output) {
observeEvent(input$submit, {
output$text <- renderText({
games1 <- switch(input$Q1,
"Yes" = "I am quite disappointed...",
"No" = "That's very good!",
)
})
}
)
}
shinyApp(ui, server)
my_df <-
data.frame(
actual = valid.set[, 4],
predicted_knn = predicted,
predicted_tree = predicted_valid,
average = (predicted + predicted_valid) / 2
)
my_df
my_df <-
data.frame(
actual = valid.set[, 4],
knn = predicted,
Regression_tree = predicted_valid,
Ensemble_Method = (predicted + predicted_valid) / 2
)
my_df
runApp('Weight_Predictor')
